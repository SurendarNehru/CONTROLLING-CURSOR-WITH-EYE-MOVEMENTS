## Controlling Cursor With Eye Movements

The mouse-free cursor control system was developed to improve user experience in computer systems as one of the accessibility improvement products for users with mobility impairments and as an innovative interaction technique.

## About
<!--Detailed Description about the project-->
The "Controlling Cursor with Eye Movements" project should achieve hands-free cursor control with the help of computer vision technology. In this sense, the novel system captures eye movements in real time using a standard webcam. Using the OpenCV and MediaPipe libraries, the project successfully identifies locations of important facial landmarks about the eyes for establishing positions to place the cursor.

This project improves accessibility for users with impaired mobility through intuitive interaction with their devices. It demonstrates how contemporary technologies can be employed to introduce accessible, user-orientated solutions with multiple needs. With a growing digital interface base, accessibility issues should be highlighted.

The capabilities include functionalities such as moving the cursor based on eye position and a click functionality performed by doing a simple gesture with the eye. Focusing on the user experience, the project suggests a development that would allow enabling assistive technologies for the users.

Overall, the work was meant to emphasize what eye-tracking technology could do and how computing should become accessible to everyone. It then helped the users thereafter in interacting effectively with their computers, thereby improving their general interaction and productivity.

## Features
<!--List the features of the project as shown below-->
- Uses computer vision technology for real-time eye tracking
- Enables hands-free cursor control for better accessibility
- Uses open CV and MediaPipe libraries while using facial landmark detection
- Supports easy navigation through eyes
- Holds click functionality based on certain eye gesture
- Intended to improve user experience among those with mobility impairments
- Suits the use of standard webcams, thus suitable for a large audience
- Simple setup with less hardware requirement
- It represents various prospects of assistive technologies in computing.
- It offers an interactive interface for the user to interact with the device.

## Requirements
<!--List the requirements of the project as shown below-->
* Operating System: Requires a 64-bit OS (Windows 10 or Ubuntu) for compatibility with computer vision libraries.
* Development Environment: Python 3.7 or later is necessary for coding the eye movement control system.
* Computer Vision Libraries: OpenCV for image processing and MediaPipe for eye landmark detection.
* Automation Libraries: PyAutoGUI for simulating mouse movements and clicks based on eye position.
* Webcam: A standard webcam is required for capturing real-time video input for eye tracking.
* Version Control: Implementation of Git for collaborative development and effective code management.
* IDE: Use of PyCharm or any suitable IDE for coding, debugging, and managing the project.
* Additional Dependencies: Includes OpenCV, MediaPipe, and PyAutoGUI for functionality and interaction with the system.







## System Architecture
<!--Embed the system architecture diagram as shown below-->

![System architecture](https://github.com/user-attachments/assets/63e3c796-08af-4c48-b820-5a3101e4a6d7)



## Output

<!--Embed the Output picture at respective places as shown below as shown below-->
#### Output1 - Code Implemantation

![Screenshot 2024-10-26 101559](https://github.com/user-attachments/assets/f37be419-9bf2-46db-bec6-e1a17ccda111)



#### Output2 - Cursor Movement

![Screenshot 2024-10-26 101836](https://github.com/user-attachments/assets/94c181e9-1f51-49bf-9026-deb0ccf46397)


## Results and Impact
<!--Give the results and impact as shown below-->
The "Controlling Cursor With Eye Movements" is one project that has great results in the means of communication between the user and the computer system, even using new technologies such as eye-tracking. Many users have felt a more intuitive and accessible way of interacting with their devices, especially those with mobility impairments. Real-time tracking enables fluid movement and accurate clicking, thus assisting users in engaging effectively without using input devices.

This project affects the individual user but also helps draw attention to the need for technology accessibility and prompts further research on assistive technologies. The scope of using eye-tracking systems was therefore demonstrated, with more emphasis on application development in an inclusive manner to service diverse users.

## Articles published / References

1.Jacob, R. J. K. (1991). The use of eye movements in human-computer interaction techniques: What you look at is what you get. ACM Transactions on Information Systems, 9(2), 152-169. DOI: 10.1145/123078.128728.

2.Duchowski, A. T. (2002). A breadth-first survey of eye-tracking applications. Behavior Research Methods, Instruments, & Computers, 34(4), 455-470. DOI: 10.3758/BF03195475.

3.Zhai, S., Morimoto, C., & Ihde, S. (1999). Manual and gaze input cascaded (MAGIC) pointing. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pp. 246-253. DOI: 10.1145/302979.303053.
